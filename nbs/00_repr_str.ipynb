{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from typing import Optional, Union\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "class __PrinterOptions(object):\n",
    "    precision: int = 3\n",
    "    threshold_max: int = 3 # .abs() larger than 1e3 -> Sci mode\n",
    "    threshold_min: int = -4 # .abs() smaller that 1e-4 -> Sci mode\n",
    "    sci_mode: Optional[bool] = None # None = auto. Otherwise, force sci mode.\n",
    "    indent: int = 2 # Indent for .deeper()\n",
    "    color: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "PRINT_OPTS = __PrinterOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |exporti\n",
    "# Do we want this float in decimal or scientific mode?\n",
    "def sci_mode(f: float):\n",
    "    return (abs(f) < 10**(PRINT_OPTS.threshold_min) or\n",
    "            abs(f) > 10**PRINT_OPTS.threshold_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(sci_mode(1.), False)\n",
    "test_eq(sci_mode(0.00001), True)\n",
    "test_eq(sci_mode(10000000), True)\n",
    "\n",
    "# It would be fine either way, both `e` and `f` formats handle those.\n",
    "test_eq(sci_mode(float('nan')), False)\n",
    "test_eq(sci_mode(float('inf')), True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{:.4e}', '1.2300e+00')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |hide\n",
    "\n",
    "# What's happening in the cell below\n",
    "fmt = f\"{{:.{4}{'e'}}}\"\n",
    "fmt, fmt.format(1.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "# Convert a tensor or scalar into a string.\n",
    "# This only looks good for small tensors, which is how it's intended to be used.\n",
    "def pretty_str(t: Union[torch.Tensor, float, int]):\n",
    "    \"\"\"A slightly better way to print `floaty` values\"\"\"\n",
    "\n",
    "    if isinstance(t, int):\n",
    "        return '{}'.format(t)\n",
    "    elif isinstance(t, float):\n",
    "        if t == 0.:\n",
    "            return \"0.\"\n",
    "\n",
    "        sci = (PRINT_OPTS.sci_mode or\n",
    "                (PRINT_OPTS.sci_mode is None and sci_mode(t)))\n",
    "        # The f-string will generate something like \"{.4f}\", which is used\n",
    "        # to format the value.\n",
    "        return f\"{{:.{PRINT_OPTS.precision}{'e' if sci else 'f'}}}\".format(t)\n",
    "    elif t.dim() == 0:\n",
    "            return pretty_str(t.item())\n",
    "    else:\n",
    "        slices = [pretty_str(t[i]) for i in range(0, t.size(0))]\n",
    "        return '[' + \", \".join(slices) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "torch.manual_seed(42)\n",
    "randoms = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasties = randoms[:12].clone()\n",
    "\n",
    "nasties[0] *= 10000\n",
    "nasties[1] /= 10000\n",
    "nasties[3] = float('inf')\n",
    "nasties[4] = float('-inf')\n",
    "nasties[5] = float('nan')\n",
    "nasties = nasties.reshape((2,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[1.927e+04, 0.000, 0.901, inf, -inf, nan], [-0.043, -1.605, -0.752, 1.649, -0.392, -1.404]]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_str(nasties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(pretty_str(nasties), '[[1.927e+04, 0.000, 0.901, inf, -inf, nan], [-0.043, -1.605, -0.752, 1.649, -0.392, -1.404]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "# |hide\n",
    "def space_join(lst):\n",
    "    # Join non-empty list elements into a space-sepaeated string\n",
    "    return \" \".join( [ l for l in lst if l] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(space_join([\"Hello\", None, \"World\"]), 'Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "class StrProxy():\n",
    "    def __init__(self, t: torch.Tensor, plain=False, verbose=False, depth=0, lvl=0, color=None):\n",
    "        self.t = t\n",
    "        self.plain = plain\n",
    "        self.verbose = verbose\n",
    "        self.depth=depth\n",
    "        self.lvl=lvl\n",
    "        self.color=color\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def to_str(self):\n",
    "        t = self.t\n",
    "        if self.plain or t.is_complex():\n",
    "            return torch._tensor_str._tensor_str(t, indent=0)\n",
    "\n",
    "        color = PRINT_OPTS.color if self.color is None else self.color\n",
    "        \n",
    "        grey_style = \"\\x1b[38;2;127;127;127m\" if color else \"\"\n",
    "        red_style = \"\\x1b[31m\" if color else \"\"\n",
    "        end_style = \"\\x1b[0m\" if color else \"\"\n",
    "\n",
    "        dtnames = { torch.float32: \"\",\n",
    "                    torch.float16: \"f16\",\n",
    "                    torch.float64: \"f64\",\n",
    "                    torch.uint8: \"u8\",\n",
    "                    torch.int32: \"i32\",\n",
    "                }\n",
    "\n",
    "\n",
    "        tname = \"tensor\" if type(t) is torch.Tensor else type(t).__name__\n",
    "        dev = str(t.device) if t.device.type != \"cpu\" else None\n",
    "        dtype = dtnames[t.dtype] if t.dtype in dtnames else str(t.dtype)[6:]\n",
    "\n",
    "\n",
    "        grad_fn = t.grad_fn.name() if t.grad_fn else None\n",
    "        # All tensors along the compute path actually have required_grad=True.\n",
    "        # Torch __repr__ just dones not show it.\n",
    "        grad = \"grad\" if t.requires_grad else None\n",
    "\n",
    "        shape = str(list(t.shape))\n",
    "\n",
    "        # Later, we might be indexing 't' with a bool tensor derived from it. \n",
    "        # THis takes 4x memory and will result in a CUDA OOM if 't' is very large.\n",
    "        # Move it to the cpu now - it won't matter for small tensors, and for\n",
    "        # very large ones we trade a CUDA OOM for a few seconds delay.\n",
    "        t = t.detach().cpu()\n",
    "\n",
    "        zeros = grey_style+\"all_zeros\"+end_style if t.eq(0.).all() and t.numel() > 1 else None\n",
    "        pinf = red_style+\"+inf!\"+end_style if t.isposinf().any() else None\n",
    "        ninf = red_style+\"-inf!\"+end_style if t.isneginf().any() else None\n",
    "        nan = red_style+\"nan!\"+end_style if t.isnan().any() else None\n",
    "\n",
    "\n",
    "        attention = space_join([zeros,pinf,ninf,nan])\n",
    "\n",
    "        x = \"\"\n",
    "        summary = f\"n={t.numel()}\" if t.numel() > 5 else None\n",
    "        if not zeros:\n",
    "            if t.numel() <= 10: x = pretty_str(t)\n",
    "            \n",
    "            # Make sure it's float32. Also, we calculate stats on good values only.\n",
    "\n",
    "            ft = t[ torch.isfinite(t) ].float()\n",
    "\n",
    "            minmax = f\"x∈[{pretty_str(ft.min())}, {pretty_str(ft.max())}]\" if t.numel() > 2 and ft.numel() > 2 else None\n",
    "            meanstd = f\"μ={pretty_str(ft.mean())} σ={pretty_str(ft.std())}\" if t.numel() >= 2 and ft.numel() >= 2 else None\n",
    "            numel = f\"n={t.numel()}\" if t.numel() > 5 and max(t.shape) != t.numel() else None\n",
    "\n",
    "            summary = space_join([numel, minmax, meanstd])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        res = tname + space_join([  shape,\n",
    "                                    summary,\n",
    "                                    dtype,\n",
    "                                    grad,\n",
    "                                    grad_fn,\n",
    "                                    dev,\n",
    "                                    attention,\n",
    "                                    x if not self.verbose else None])\n",
    "\n",
    "        if self.verbose:\n",
    "            res += \"\\n\" + torch._tensor_str._tensor_str(t, indent=0)\n",
    "\n",
    "        if self.depth and t.dim() > 1:\n",
    "            res += \"\\n\" + \"\\n\".join([\n",
    "                \" \"*PRINT_OPTS.indent*(self.lvl+1) +\n",
    "                str(StrProxy(t[i,:], depth=self.depth-1, lvl=self.lvl+1))\n",
    "                for i in range(t.shape[0])])\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.to_str()\n",
    "\n",
    "    def __call__(self, depth=0):\n",
    "        return StrProxy(self.t, depth=depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Would be _lovely_ if you could see all the important tensor stats too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def lovely(t: torch.Tensor, verbose=False, plain=False, depth=0, color=None):\n",
    "    return StrProxy(t, verbose=verbose, plain=plain, depth=depth, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[] 1.927\n",
      "tensor[2] μ=1.707 σ=0.311 [1.927, 1.487]\n",
      "tensor[2, 3] n=6 x∈[-2.106, 1.927] μ=0.276 σ=1.594 [[1.927, 1.487, 0.901], [-2.106, 0.678, -1.235]]\n",
      "tensor[11] x∈[-2.106, 1.927] μ=0.046 σ=1.384\n"
     ]
    }
   ],
   "source": [
    "print(lovely(randoms[0]))\n",
    "print(lovely(randoms[:2]))\n",
    "print(lovely(randoms[:6].view(2, 3))) # More than 2 elements -> show statistics\n",
    "print(lovely(randoms[:11])) # More than 10 -> suppress data output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(str(lovely(randoms[0])), \"tensor[] 1.927\")\n",
    "test_eq(str(lovely(randoms[:2])), \"tensor[2] μ=1.707 σ=0.311 [1.927, 1.487]\")\n",
    "test_eq(str(lovely(randoms[:6].view(2, 3))), \"tensor[2, 3] n=6 x∈[-2.106, 1.927] μ=0.276 σ=1.594 [[1.927, 1.487, 0.901], [-2.106, 0.678, -1.235]]\")\n",
    "test_eq(str(lovely(randoms[:11])), \"tensor[11] x∈[-2.106, 1.927] μ=0.046 σ=1.384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[] grad 1.000\n",
      "tensor[] grad AddBackward0 2.000\n"
     ]
    }
   ],
   "source": [
    "grad = torch.tensor(1., requires_grad=True)\n",
    "print(lovely(grad)); print(lovely(grad+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(str(lovely(grad)), \"tensor[] grad 1.000\")\n",
    "test_eq(str(lovely(grad+1)), \"tensor[] grad AddBackward0 2.000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[] cuda:0 1.000\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(lovely(torch.tensor(1., device=torch.device(\"cuda:0\"))))\n",
    "    test_eq(str(lovely(torch.tensor(1., device=torch.device(\"cuda:0\")))), \"tensor[] cuda:0 1.000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have __any__ floating point nasties? Is the tensor __all__ zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRINT_OPTS.color=True\n",
    "\n",
    "# Statistics and range are calculated on good values only, if there are at lest 3 of them.\n",
    "lovely(nasties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 +inf! -inf! nan!"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(nasties, color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[11] \u001b[31mnan!\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(torch.tensor([float(\"nan\")]*11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[12] n=12 \u001b[38;2;127;127;127mall_zeros\u001b[0m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(torch.zeros(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(str(lovely(nasties)),\n",
    "    'tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 \\x1b[31m+inf!\\x1b[0m \\x1b[31m-inf!\\x1b[0m \\x1b[31mnan!\\x1b[0m')\n",
    "test_eq(str(lovely(torch.tensor([float(\"nan\")]*11))), 'tensor[11] \\x1b[31mnan!\\x1b[0m')\n",
    "test_eq(str(lovely(torch.zeros(12))), 'tensor[12] n=12 \\x1b[38;2;127;127;127mall_zeros\\x1b[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m\n",
       "[[ 1.9269e+04,  1.4873e-04,  9.0072e-01,         inf,        -inf,         nan],\n",
       " [-4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(linewidth=120)\n",
    "lovely(nasties, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ 1.9269e+04,  1.4873e-04,  9.0072e-01,         inf,        -inf,         nan],\n",
       " [-4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lovely(nasties, plain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[3, 196, 196] n=115248 x∈[-2.118, 2.640] μ=-0.388 σ=1.073 \u001b[31mnan!\u001b[0m\n",
       "  tensor[196, 196] n=38416 x∈[-2.118, 2.249] μ=-0.324 σ=1.036\n",
       "  tensor[196, 196] n=38416 x∈[-1.966, 2.429] μ=-0.274 σ=0.973 \u001b[31mnan!\u001b[0m\n",
       "  tensor[196, 196] n=38416 x∈[-1.804, 2.640] μ=-0.567 σ=1.178"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.load(\"mysteryman.pt\")\n",
    "image[1,100,100] = float('nan')\n",
    "\n",
    "lovely(image, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before allocation: torch.cuda.memory_allocated()=0\n",
      "after allocation: torch.cuda.memory_allocated()=12582912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor[3, 1024, 1024] n=3145728 x∈[-5.325, 5.150] μ=-0.000 σ=0.999 cuda:0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after repr: torch.cuda.memory_allocated()=12582912\n",
      "after cleanup: torch.cuda.memory_allocated()=0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cudamem = torch.cuda.memory_allocated()\n",
    "    print(f\"before allocation: {torch.cuda.memory_allocated()=}\")\n",
    "    numbers = torch.randn((3, 1024, 1024), device=\"cuda\") # 12Mb image\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(f\"after allocation: {torch.cuda.memory_allocated()=}\")\n",
    "    # Note, the return value of lovely() is not a string, but a\n",
    "    # StrProxy that holds reference to 'numbers'. You have to del\n",
    "    # any references to it.\n",
    "    display(lovely(numbers) )\n",
    "    print(f\"after repr: {torch.cuda.memory_allocated()=}\")\n",
    "    \n",
    "    del numbers\n",
    "    # torch.cuda.memory.empty_cache()\n",
    "\n",
    "    print(f\"after cleanup: {torch.cuda.memory_allocated()=}\")\n",
    "    test_eq(cudamem >= torch.cuda.memory_allocated(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5135+0.0645j, -0.2751+0.3733j, -0.2552-0.0428j,  0.0518+0.5789j,  1.0469+0.2439j, -1.0070-0.0823j,\n",
       "         0.1538-0.0330j, -1.0137-0.4006j, -0.3007+0.1856j, -1.0176+0.3687j])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't really supposed complex numbers yet\n",
    "c = torch.randn(10, dtype=torch.complex64)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
